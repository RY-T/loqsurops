#For files in Init/
FT_list= [line.rstrip('\n') for line in open('Init/Gff_to_bed/feature_type_list.txt')]
PT_list= [line.rstrip('\n') for line in open('Init/Gff_to_bed/parent_type_list.txt')]
Exon_PT_list= [line.rstrip('\n') for line in open('Init/Gff_to_bed/exon_parent_type_list.txt')]
Strand =['plus', 'minus']
Intersect_type=['exon','gene']
Intersect_samples =['Index_gen/Gff_to_bed/dm6.17_flybase_FT_exon_PTID.merge', 'Index_gen/Gff_to_bed/dm6.17_flybase_FT_gene_GeneID' ]
Cisnat_list_1= [line.rstrip('\n') for line in open('Init/Gff_to_bed/cisnat_type_list_1.txt')]
Cisnat_list_2 = [line.rstrip('\n') for line in open('Init/Gff_to_bed/cisnat_type_list_2.txt')]

CHR_LIST= [line.rstrip('\n') for line in open('Init/Repeat_Masker/Chr_list.txt')]
RM_GENETYPES=['LTR','LINE','DNA','Satellite','Low_complexity','RC','Simple_repeat','Other','Unknown','ARTEFACT','RNA','rRNA','tRNA']
Flybase_GENETYPES2=['rRNA', 'tRNA', 'snRNA', 'snoRNA']
RepeatMasker_Dir='/usr/local/RepeatMasker/RepeatMasker'
Modified_bed_files=[]
fasta_file_path = []

rule all:
	input:
		'Index_gen/Gff_to_bed/dm6.17_flybase.gff','Index_gen/Gff_to_bed/dm6.17_flybase_FTcounts.txt',
		expand('Index_gen/Gff_to_bed/dm6.17_flybase_FT_{FT}.gff', FT=FT_list), 
		expand('Index_gen/Gff_to_bed/transcript_PT_identifiers/dm6.17_flybase_FT_{FT}.gff.PTID', FT=PT_list),
		expand('Index_gen/Gff_to_bed/transcript_PT_identifiers/dm6.17_flybase_FT_{FT}.gff.geneID', FT=Exon_PT_list),
		'Index_gen/Gff_to_bed/dm6_flybase.db',
		expand('Index_gen/Gff_to_bed/transcript_PT_identifiers/dm6.17_flybase_FT_{PT}.gff.PTID_FT_exon', PT=Exon_PT_list),
		'Index_gen/Gff_to_bed/dm6.17_flybase_FT_exon_PTID.gff','Index_gen/Gff_to_bed/dm6.17_flybase_FT_exon_PTID.bed',
		expand('Index_gen/Gff_to_bed/transcript_PT_identifiers/dm6.17_flybase_FT_gene_GeneType_{GT}.gff', GT=Exon_PT_list),
		'Index_gen/Gff_to_bed/dm6.17_flybase_FT_gene_GeneID.gff','Index_gen/Gff_to_bed/dm6.17_flybase_FT_gene_GeneID.bed',
		'Index_gen/Gff_to_bed/dm6.17_flybase_FT_exon_PTID.merge.bed',
		expand('Index_gen/Gff_to_bed/dm6.17_flybase_FT_exon_PTID.merge.{strand}.bed', strand=Strand),
		expand('Index_gen/Gff_to_bed/dm6.17_flybase_FT_gene_GeneID.{strand}.bed', strand=Strand),
		expand('{sample}.intersect.bed' , sample=Intersect_samples),
		expand('{sample}.intersect.ID.bed',sample=Intersect_samples),
		'Index_gen/Gff_to_bed/dm6.17_flybase_exonintersect_mapto_geneintersect.bed', 
		'Index_gen/Gff_to_bed/intersect_bedfiles/counts.txt',
		'Index_gen/Gff_to_bed/intersect_bedfiles/dm6.17_flybase_FT_exon_alltypes.intersect.ID.bed',
		expand('Index_gen/Gff_to_bed/intersect_bedfiles/dm6.17_flybase_FT_exon_{type1}.intersect.ID.bed', type1=Cisnat_list_1),
		expand('Index_gen/Gff_to_bed/intersect_bedfiles/dm6.17_flybase_FT_exon_{type2}.intersect.ID.bed', type2=Cisnat_list_2),
		expand('Index_gen/Gff_to_bed/raw_exon_TE_bedfiles/dm6.17_flybase_FT_exon_PT_{PT}.bed', PT=Exon_PT_list),
		expand('Index_gen/Gff_to_bed/merged_bedfiles/dm6.17_flybase_FT_exon_PT_{PT}.merge.bed', PT=Exon_PT_list),
		'Index_gen/Gff_to_bed/raw_exon_TE_bedfiles/dm6.17_flybase_FT_transposable_element.bed',
		'Index_gen/Gff_to_bed/merged_bedfiles/dm6.17_flybase_FT_transposable_element.merge.bed',
		'Index_gen/Repeat_Masker/Index0.fa',
		'Index_gen/Repeat_Masker/RM_output',
		expand('Index_gen/Repeat_Masker/modified_bed/{RM_Genetype}RM.bed', RM_Genetype=RM_GENETYPES),
		'Index_gen/Repeat_Masker/modified_bed/RNAonlyRM.bed',
		'Index_gen/Repeat_Masker/modified_bed/pri_miRNA_mirbase21_dm6.bed',
		'Index_gen/Repeat_Masker/modified_bed.test.txt',
		'Index_gen/Repeat_Masker/modified_bed/fasta/test.txt',
		'Index_gen/Repeat_Masker/modified_bed/fasta/test2.txt',
		'Index_gen/Repeat_Masker/modified_bed/fasta/Index0.fa',
		'Index_gen/Repeat_Masker/modified_bed/fasta/pri_miRNA.fa',
		'Index_gen/Repeat_Masker/modified_bed/fasta/flybasehpRNA.fa',
		'Index_gen/Repeat_Masker/modified_bed/fasta/bt_indexes/test.txt',


rule extract_flybase_to_bed_format:
	input:
		in_gff = 'Input_files/Flybase_downloads/dmel-all-r6.17.gff'
	output:
		out_gff = 'Index_gen/Gff_to_bed/dm6.17_flybase.gff', out_FTcounts = 'Index_gen/Gff_to_bed/dm6.17_flybase_FTcounts.txt'
	run:
		import os
		import pandas as pd
		from pathlib import Path
		out_dir=Path('Index_gen/Gff_to_bed')
		if out_dir.is_dir() != True:
			os.mkdir('Index_gen/Gff_to_bed')
		#Note, end limit here has to be hardcoded? # line 1874 for DM6.17
		#Start: End of fasta, 23278924:25080161
		#First fasta is >211000022280479
		#last fasta is >211000022280192
		shell("sed '1,1874d' {input} | sed '23278924,25080161d' > dm6.17_temp.gff")
		gff = pd.read_csv('dm6.17_temp.gff', sep='\t', header=None, index_col=None)
		flybase = gff[gff[1].str.contains("^FlyBase", na=False)]
		#flybase[0] = flybase[0].str.replace('dmel_mitochondrion_genome', 'M')
		flybase[0] = 'chr' + flybase[0].astype(str)
		flybase[3] = flybase[3].astype(int)
		flybase[4] = flybase[4].astype(int)
		FTcounts = flybase.groupby([2]).size()
		#Note, fix this line such that it also gives names

		flybase.to_csv(output.out_gff, sep='\t', header=None, index=False)
		FTcounts.to_csv(output.out_FTcounts, sep='\t', header=None, index=False)
		shell("rm dm6.17_temp.gff")

rule split_gff_by_FeatureType:
	input:
		in_gff = 'Index_gen/Gff_to_bed/dm6.17_flybase.gff'
	output:
		out_gff = expand('Index_gen/Gff_to_bed/dm6.17_flybase_FT_{FT}.gff', FT=FT_list)
	run:
		import pandas as pd
		gff = pd.read_csv(input.in_gff, sep='\t', header=None, index_col=None)

		for feature in FT_list:
			FT_gff = gff.loc[gff[2] == feature]
			FT_gff.to_csv("Index_gen/Gff_to_bed/dm6.17_flybase_FT_" + str(feature) + ".gff", sep='\t',header=None, index=False)

rule extract_transcript_gene_ID:
	input:
		in_gff = expand('Index_gen/Gff_to_bed/dm6.17_flybase_FT_{FT}.gff', FT=PT_list),
		in_gene_gff = expand('Index_gen/Gff_to_bed/dm6.17_flybase_FT_{FT}.gff', FT=Exon_PT_list)
	output:
		out_ID = expand('Index_gen/Gff_to_bed/transcript_PT_identifiers/dm6.17_flybase_FT_{FT}.gff.PTID', FT=PT_list),
		out_gene_ID = expand('Index_gen/Gff_to_bed/transcript_PT_identifiers/dm6.17_flybase_FT_{FT}.gff.geneID', FT=Exon_PT_list)
	run:
		import pandas as pd
		shell("mkdir -p Index_gen/Gff_to_bed/transcript_PT_identifiers'")

		for gff in input.in_gff:
			gffdata = pd.read_csv(gff,sep='\t', header=None, index_col=None)
			split_PTID_field = (gffdata[8].str.split(';',expand=True))[0]
			split_geneID_field = (gffdata[8].str.split(';',expand=True))[2]
			PTID = (split_PTID_field.str.split('=',expand=True))[1]
			geneID = (split_geneID_field.str.split('=',expand=True))[1]
			geneID = geneID.drop_duplicates()
			geneID = 'ID=' + geneID
			PTID.to_csv(os.path.join('Index_gen/Gff_to_bed/transcript_PT_identifiers/', gff + '.PTID'),sep='\t', header=None, index=False)
			geneID.to_csv(os.path.join('Index_gen/Gff_to_bed/transcript_PT_identifiers/', gff + '.geneID'),sep='\t', header=None, index=False)

rule define_exon_PT:
	input:
		in_ID = expand('Index_gen/Gff_to_bed/transcript_PT_identifiers/dm6.17_flybase_FT_{PT}.gff.PTID', PT=Exon_PT_list),
		in_gff = 'Index_gen/Gff_to_bed/dm6.17_flybase.gff'
	output:
		out_gff = expand('Index_gen/Gff_to_bed/transcript_PT_identifiers/dm6.17_flybase_FT_{PT}.gff.PTID_FT_exon', PT=Exon_PT_list),
		database = 'Index_gen/Gff_to_bed/dm6_flybase.db'
	run:
		import pandas as pd
		import gffutils
		gffutils.create_db(input.in_gff, dbfn= output.database, force=True, keep_order=True,merge_strategy='merge', sort_attribute_values=True)
		db = gffutils.FeatureDB(output.database, keep_order=True)

		for PTID in input.in_ID:
			IDs = [line.rstrip('\n') for line in open(PTID)]
			sys.stdout = open( PTID + "_FT_exon", "w")
			for ID in IDs:
				children = db.children(ID, featuretype='exon')
				for feature in children:
					print (feature)
#
rule combine_exon_files_with_PTID_and_convert_to_bed:
	input:
		in_gff= expand('Index_gen/Gff_to_bed/transcript_PT_identifiers/dm6.17_flybase_FT_{PT}.gff.PTID_FT_exon', PT=Exon_PT_list)
	output:
		out_gff= 'Index_gen/Gff_to_bed/dm6.17_flybase_FT_exon_PTID.gff',
		out_bed= 'Index_gen/Gff_to_bed/dm6.17_flybase_FT_exon_PTID.bed'
	run:
		import pandas as pd
		counter = 0
		df = pd.DataFrame()
		for gff in input.in_gff:
			currentPT = Exon_PT_list[counter]
			gffdata = pd.read_csv(gff,sep='\s+',header=None, index_col=None)
			dropdata = gffdata.drop_duplicates()
			Strand = ";ExStrand=" + dropdata[dropdata.columns[6]].astype(str)
			Start = ";ExStart=" + dropdata[dropdata.columns[3]].astype(str)
			Length = ";ExLength=" + (dropdata[dropdata.columns[4]].astype(int) - dropdata[dropdata.columns[3]].astype(int)).astype(str)
			dropdata[8] = dropdata[8].astype(str) + Strand.astype(str) + Start.astype(str) + Length.astype(str) + ";Parenttype=" + currentPT
			df = df.append(dropdata)
			counter += 1
		bed = df
		bed[9] = bed[bed.columns[4]].astype(int) - bed[bed.columns[3]].astype(int)
		bed = bed.drop(bed[bed[9] <= 0].index)
		bed = bed[[0,3,4,8,5,6]]

		df.to_csv('Index_gen/Gff_to_bed/dm6.17_flybase_FT_exon_PTID.gff',sep='\t', header=None, index=False)
		bed.to_csv('Index_gen/Gff_to_bed/dm6.17_flybase_FT_exon_PTID.bed',sep='\t', header=None, index=False)


rule label_gene_with_Genetype:
	input:
		in_ID = expand('Index_gen/Gff_to_bed/transcript_PT_identifiers/dm6.17_flybase_FT_{FT}.gff.geneID', FT=Exon_PT_list),
		in_gff = 'Index_gen/Gff_to_bed/dm6.17_flybase_FT_gene.gff'
	output:
		out_gff = expand('Index_gen/Gff_to_bed/transcript_PT_identifiers/dm6.17_flybase_FT_gene_GeneType_{GT}.gff', GT=Exon_PT_list)
	run:
		import pandas as pd
		counter = 0
		gff = [line.rstrip('\n') for line in open(input.in_gff)]

		for in_file in input.in_ID:
			current_GeneType = Exon_PT_list[counter]
			ID_list = [line.rstrip('\n') for line in open(in_file)]
			out_file = open(os.path.join('Index_gen/Gff_to_bed/transcript_PT_identifiers/','dm6.17_flybase_FT_gene_GeneType_' + current_GeneType + '.gff'),"w")
			counter += 1
			for ID in ID_list:
				for entry in gff:
					if ID in entry:
						entry = entry + "\t" + "GeneType=" + current_GeneType
						out_file.write(entry + '\n')

rule combine_Genetypes_convert_to_bed:
	input:
		in_gff = expand('Index_gen/Gff_to_bed/transcript_PT_identifiers/dm6.17_flybase_FT_gene_GeneType_{GT}.gff', GT=Exon_PT_list)
	output:
		out_gff = 'Index_gen/Gff_to_bed/dm6.17_flybase_FT_gene_GeneID.gff', out_bed = 'Index_gen/Gff_to_bed/dm6.17_flybase_FT_gene_GeneID.bed'
	run:
		import pandas as pd
		c_gff = pd.DataFrame()

		for gff in input.in_gff:
			gffdata = pd.read_csv(gff,sep='\t',header=None, index_col=None)
			c_gff = c_gff.append(gffdata)

		field = (c_gff[8].str.split(';',expand=True))
		ID = field[field.columns[0]]
		Strand= ";GnStrand=" + c_gff[c_gff.columns[6]].astype(str)
		Start = ";GnStart=" + c_gff[c_gff.columns[3]].astype(str)
		Length = ";Genelength=" + (c_gff[c_gff.columns[4]].astype(int) - c_gff[c_gff.columns[3]].astype(int)).astype(str)
		GeneType = ";" + c_gff[c_gff.columns[-1]].astype(str)
		ID_field = ID.astype(str) + Strand.astype(str) + Start.astype(str) + Length.astype(str) + GeneType.astype(str)
		bed = c_gff[[0,3,4,5,6]]
		bed.insert(3, column = 'ID', value = ID_field)

		c_gff.to_csv(output.out_gff,sep='\t', header=None, index=False)
		bed.to_csv('temp.bed',sep='\t', header=None, index=False)

		shell("sort-bed temp.bed > {output.out_bed}")
		shell("rm temp.bed")

#As expected im 1 gene short in the snoRNA

rule merge_exon_convert_bed:
	input:
		in_exon = 'Index_gen/Gff_to_bed/dm6.17_flybase_FT_exon_PTID.bed'
	output:
		out_merge = 'Index_gen/Gff_to_bed/dm6.17_flybase_FT_exon_PTID.merge.bed',
	run:
		import pandas as pd
		shell("sort-bed {input} | bedtools merge -s -c 4 -o collapse -i - | \
		sort-bed - > temp.merge")

		merge_exon = pd.read_csv('temp.merge',sep='\t',header=None, index_col=None)
		merge_exon_bed = merge_exon[[0,1,2,4,3]]
		merge_exon_bed.insert(4, column = 'temp', value = '.')
		merge_exon_bed.to_csv(output.out_merge,sep='\t', header=None, index=False)

		shell("rm temp.merge")

rule extract_strand_for_exon_gene:
	input:
		in_exon = 'Index_gen/Gff_to_bed/dm6.17_flybase_FT_exon_PTID.merge.bed',
		in_gene = 'Index_gen/Gff_to_bed/dm6.17_flybase_FT_gene_GeneID.bed'
	output:
		out_exon = expand('Index_gen/Gff_to_bed/dm6.17_flybase_FT_exon_PTID.merge.{strand}.bed', strand=Strand),
		out_gene = expand('Index_gen/Gff_to_bed/dm6.17_flybase_FT_gene_GeneID.{strand}.bed', strand=Strand)
	run:
		import pandas as pd

		exon_bed = pd.read_csv(input.in_exon,sep='\t',header=None, index_col=None)
		gene_bed = pd.read_csv(input.in_gene,sep='\t',header=None, index_col=None)
		counter = 0
		for bed in (exon_bed, gene_bed):
			plus_features, minus_features = bed.loc[bed[5] == '+'], bed.loc[bed[5] == '-']
			counter += 1
			print(counter)
			if counter == 1 :
				plus_features.to_csv('Index_gen/Gff_to_bed/dm6.17_flybase_FT_exon_PTID.merge.plus.bed',sep='\t', header=None, index=False)
				minus_features.to_csv('Index_gen/Gff_to_bed/dm6.17_flybase_FT_exon_PTID.merge.minus.bed',sep='\t', header=None, index=False)
			else:
				plus_features.to_csv('Index_gen/Gff_to_bed/dm6.17_flybase_FT_gene_GeneID.plus.bed',sep='\t', header=None, index=False)
				minus_features.to_csv('Index_gen/Gff_to_bed/dm6.17_flybase_FT_gene_GeneID.minus.bed',sep='\t', header=None, index=False)

rule intersect_within_gene_exon_remove_gene_duplicates:
	input:
		plus = "{sample}.plus.bed",
		minus = "{sample}.minus.bed"

	output:
		'{sample}.intersect.bed'
	run:
		import pandas as pd
		import os.path

		shell("bedtools intersect -S -a {input.plus} -b {input.minus} -bed | \
		sort-bed - > {output}")
		#Note, here is how you coordinate your input files, and you dont need wildcards.
		#however, you do need to expand a list of your output files in rule all though.
		gene_bed = 'Index_gen/Gff_to_bed/dm6.17_flybase_FT_gene_GeneID.intersect.bed'
		if os.path.isfile(gene_bed):
			intersect_data = pd.read_csv(gene_bed,sep='\t',header=None, index_col=None)
			intersect_data = intersect_data.drop_duplicates()
			intersect_data.to_csv(gene_bed,sep='\t', header=None, index=False)
		else:
			pass

#nte, the resultant gene.intersect file has duplicate features why?
#But the resultant exon file does not.
#Oh my god, editing one file in the early chain -> changes everything dowstream
#Note .columns is for single columns, while [[]] is for multiple columnds

rule map_to_original_bed_for_intersect_ID:
	input:
		intersect = "{sample}.intersect.bed",
		bed = "{sample}.bed"
	output:
		'{sample}.intersect.ID.bed'

	run:
		import pandas as pd
		import os
		shell("bedtools map -c 4 -o collapse -a {input.intersect} -b {input.bed} | \
		sort-bed - > {output}")
		exon_inter, gene_inter = expand('{sample}.intersect.ID.bed',sample=Intersect_samples)
		#exon_inter='Index_gen/Gff_to_bed/dm6.17_flybase_FT_exon_PTID.merge.intersect.ID.bed'
		def extract_ID_bed(bedfile):
			data = pd.read_csv(bedfile,sep='\t',header=None, index_col=None)
			data = data[[0,1,2,6,4,5]]
			data.to_csv(bedfile,sep='\t', header=None, index=False)

		if os.path.isfile(exon_inter) and os.path.isfile(gene_inter):
			extract_ID_bed(exon_inter)
			extract_ID_bed(gene_inter)
		else:
			pass

#Here we map back to the orignal bed file to get the details of both parts of
#intersect.

rule map_exon_intersect_to_gene_intersect:
	input:
		exon = 'Index_gen/Gff_to_bed/dm6.17_flybase_FT_exon_PTID.merge.intersect.ID.bed',
		gene = 'Index_gen/Gff_to_bed/dm6.17_flybase_FT_gene_GeneID.intersect.ID.bed'
	output:
		'Index_gen/Gff_to_bed/dm6.17_flybase_exonintersect_mapto_geneintersect.bed'
	shell:"""
		bedtools map -c 4 -o collapse -a {input.exon} -b {input.gene} | \
		sort-bed - > {output}
		"""
#K, every feature in exon was mapped, good sign.
#This is just to provide,

rule split_exon_intersect_into_type:
	input:
		in_bed = 'Index_gen/Gff_to_bed/dm6.17_flybase_FT_exon_PTID.merge.intersect.ID.bed'
	output:
		count = 'Index_gen/Gff_to_bed/intersect_bedfiles/counts.txt',
		alltypes = 'Index_gen/Gff_to_bed/intersect_bedfiles/dm6.17_flybase_FT_exon_alltypes.intersect.ID.bed',
		mixed = expand('Index_gen/Gff_to_bed/intersect_bedfiles/dm6.17_flybase_FT_exon_{type1}.intersect.ID.bed', type1=Cisnat_list_1),
		same = expand('Index_gen/Gff_to_bed/intersect_bedfiles/dm6.17_flybase_FT_exon_{type2}.intersect.ID.bed', type2=Cisnat_list_2)
	run:
		import pandas as pd
		import os
		shell("mkdir -p Index_gen/Gff_to_bed/intersect_bedfiles")
		match_list_2 = \
		["{'Parenttype=mRNA'}","{'Parenttype=pre_miRNA'}", "{'Parenttype=snoRNA'}", "{'Parenttype=ncRNA'}", \
		"{'Parenttype=pseudogene'}", "{'Parenttype=tRNA'}", "{'Parenttype=rRNA'}", "{'Parenttype=snRNA'}"]

		row_acc, final_acc, counter = (),(), 0
		data = pd.read_csv(input.in_bed,sep='\t',header=None, index_col=None)
		ID_field = data[3].str.replace(',', ';')
		ID_split = (ID_field.str.split(';',expand=True))

		for index, row in ID_split.iterrows():
			for ele in row:
				if ele == None:
					pass
				elif 'Parenttype=' in ele:
					row_acc += (ele,)
			final_acc += (str(set(row_acc)),)
			row_acc = ()
		typedf = pd.DataFrame(list(final_acc))
		data[6] = typedf
		intersectcounts = data.groupby([6]).size()

		for cisnat in Cisnat_list_1:
			type1,type2 = cisnat.split('-')
			first = data[data[6].str.contains(type1)]
			first_and_second = first[first[6].str.contains(type2)]
			finaldata1 = first_and_second[first_and_second.columns[:-1]]
			finaldata1.to_csv(os.path.join('Index_gen/Gff_to_bed/intersect_bedfiles/','dm6.17_flybase_FT_exon_' + cisnat + '.intersect.ID.bed'),sep='\t', header=None, index=False)

		for cisnat in Cisnat_list_2:
			curr_match = match_list_2[counter]
			match = data[data[6].str.contains(curr_match)]
			finaldata2 = match[match.columns[:-1]]
			finaldata2.to_csv(os.path.join('Index_gen/Gff_to_bed/intersect_bedfiles/','dm6.17_flybase_FT_exon_' + cisnat + '.intersect.ID.bed'),sep='\t', header=None, index=False)
			counter += 1

		data.to_csv(output.alltypes,sep='\t', header=None, index=False)
		intersectcounts.to_csv(output.count,sep='\t', header=None, index=False)
		shell("wc -l ./Index_gen/Gff_to_bed/intersect_bedfiles/*")

rule extract_individual_exon:
	input:
		in_exon= 'Index_gen/Gff_to_bed/dm6.17_flybase_FT_exon_PTID.bed',
		#in_TE= 'Index_gen/Gff_to_bed/dm6.17_flybase_FT_transposable_element.gff'
	output:
		out_exon = expand('Index_gen/Gff_to_bed/raw_exon_TE_bedfiles/dm6.17_flybase_FT_exon_PT_{PT}.bed', PT=Exon_PT_list),
		#out_TE = 'Index_gen/Gff_to_bed/raw_exon_TE_bedfiles/dm6.17_flybase_FT_transposable_element.bed'
	run:
		import pandas as pd
		counter = 0
		shell("mkdir -p Index_gen/Gff_to_bed/raw_exon_TE_bedfiles")
		exon_data = pd.read_csv(input.in_exon,sep='\t',header=None, index_col=None)

		for out_file in output.out_exon:
			out = exon_data[exon_data[3].str.contains(Exon_PT_list[counter])]
			out.to_csv(output.out_exon[counter], sep='\t', header=None, index=False)
			counter += 1

rule merge_exon_Type:
	input:
		in_exon ='Index_gen/Gff_to_bed/raw_exon_TE_bedfiles/dm6.17_flybase_FT_exon_PT_{PT}.bed',
		#in_TE = 'Index_gen/Gff_to_bed/raw_exon_TE_bedfiles/dm6.17_flybase_FT_transposable_element.bed'
	output:
		out_exon='Index_gen/Gff_to_bed/merged_bedfiles/dm6.17_flybase_FT_exon_PT_{PT}.merge',
		#out_TE = 'Index_gen/Gff_to_bed/merged_bedfiles/dm6.17_flybase_FT_transposable_element.merge.bed'
	run:
		import pandas as pd
		import os
		counter = 0
		shell("mkdir -p Index_gen/Gff_to_bed/merged_bedfiles")
		shell("sort-bed {input.in_exon} | bedtools merge -s -c 4 -o collapse -i - | \
		sort-bed - > {output.out_exon}")

rule convert_to_bed:
	input:
		in_exon = expand('Index_gen/Gff_to_bed/merged_bedfiles/dm6.17_flybase_FT_exon_PT_{PT}.merge', PT=Exon_PT_list)
		#in_TE = 'Index_gen/Gff_to_bed/raw_exon_TE_bedfiles/dm6.17_flybase_FT_transposable_element.bed'
	output:
		out_exon= expand('Index_gen/Gff_to_bed/merged_bedfiles/dm6.17_flybase_FT_exon_PT_{PT}.merge.bed', PT=Exon_PT_list)
	run:
		counter = 0
		import pandas as pd

		for filename in input.in_exon:
			data = pd.read_csv(filename,sep='\t',header=None, index_col=None)
			data_bed = data[[0,1,2,4,3]]
			data_bed.insert(4, column = 'temp', value = '.')
			data_bed.to_csv(output.out_exon[counter],sep='\t', header=None, index=False)
			counter += 1

rule do_for_TE:
	input:
		gff = 'Index_gen/Gff_to_bed/dm6.17_flybase_FT_transposable_element.gff'
	output:
		bed = 'Index_gen/Gff_to_bed/raw_exon_TE_bedfiles/dm6.17_flybase_FT_transposable_element.bed',
		merge_bed = 'Index_gen/Gff_to_bed/merged_bedfiles/dm6.17_flybase_FT_transposable_element.merge.bed'
	run:
		import pandas as pd
		TE_data = pd.read_csv(input.gff,sep='\t',header=None, index_col=None)

		field = (TE_data[8].str.split(';',expand=True))
		ID = field[field.columns[0]]
		TEstrand= ";TEstrand=" + TE_data[TE_data.columns[6]].astype(str)
		TEstart = ";TEstart=" + TE_data[TE_data.columns[3]].astype(str)
		TElength = ";TElength=" + (TE_data[TE_data.columns[4]].astype(int) - TE_data[TE_data.columns[3]].astype(int)).astype(str)
		ID_field = ID.astype(str) + TEstrand.astype(str) + TEstart.astype(str) + TElength.astype(str)
		TE_data = TE_data[[0,3,4,5,6]]
		TE_data.insert(3, column = 'ID', value = ID_field)
		TE_data.to_csv(output.bed, sep='\t', header=None, index=False)

		bed = 'Index_gen/Gff_to_bed/raw_exon_TE_bedfiles/dm6.17_flybase_FT_transposable_element.bed'
		merge = 'Index_gen/Gff_to_bed/merged_bedfiles/dm6.17_flybase_FT_transposable_element.merge'

		shell("sort-bed {bed} | bedtools merge -s -c 4 -o collapse -i - | \
		sort-bed - > {merge} ")

		data = pd.read_csv(merge,sep='\t',header=None, index_col=None)
		data_bed = data[[0,1,2,4,3]]
		data_bed.insert(4, column = 'temp', value = '.')
		data_bed.to_csv(output.merge_bed,sep='\t', header=None, index=False)


rule extract_impt_chr:
	input:
		genome = 'Input_files/Flybase_downloads/dmel-all-chromosome-r6.17.fasta'
	output:
		'{Chr_list}.temp'
	shell:"""
	samtools faidx {input.genome}
	samtools faidx {input.genome} {wildcards.Chr_list} > {output}
	"""
		
rule make_Index_0:
	input:
		expand('{Chr_list}.temp', Chr_list=CHR_LIST)
	output:
		'Index_gen/Repeat_Masker/Index0.fa'
	run: 
		import os
		from pathlib import Path
		out_dir=Path('Index_gen/Repeat_Masker')
		if out_dir.is_dir() != True:
			os.mkdir('Index_gen/Repeat_Masker')
		shell("""cat {input} > {output} 
			rm {input}""")

rule repeatMasker:
	input: 
		genome = 'Index_gen/Repeat_Masker/Index0.fa',
		RM_Dir = RepeatMasker_Dir
	output:
		'Index_gen/Repeat_Masker/RM_output'
	shell:"""
	mkdir -p {output} 
	{input.RM_Dir} -dir {output} -species drosophila {input.genome}
	"""
rule extract_bed_from_RMout: 
#makes modified bedfiles chr start stop
#awk command obtained from https://www.biostars.org/p/128068/
	input:
		'Index_gen/Repeat_Masker/RM_output/Index0.fa.out' 
	output:
		bedfiles='Index_gen/Repeat_Masker/modified_bed/RM_output.bed'
	params:
		RMout2bed='Input_files/Awk_scripts/RMout2bed.awk'
	run:
		import os
		from pathlib import Path
		out_dir=Path('Index_gen/Repeat_Masker/modified_bed/')
		if out_dir.is_dir() != True:
			os.mkdir('Index_gen/Repeat_Masker/modified_bed/')
		shell('''
		awk -f {params.RMout2bed} {input} > {output.bedfiles}
		''')

rule pandas_search_from_modified_bed_part1:
	input:
		bedfile = 'Index_gen/Repeat_Masker/modified_bed/RM_output.bed'
#part 1 extract RNA out first, part2 then from RNA, extract tRNA, etc...
	output: expand('Index_gen/Repeat_Masker/modified_bed/{RM_Genetype}RM.bed', RM_Genetype=RM_GENETYPES)
	run:
		import pandas as pd
		import os
		everything = pd.read_csv(input.bedfile ,sep="\t+",header=None)
		RM_Genetype	=['LTR','LINE','DNA','Satellite','Low_complexity','RC','Simple_repeat','Other','Unknown','ARTEFACT','RNA','rRNA','tRNA']
		for genetype in RM_Genetype:
			out_dir = "Index_gen/Repeat_Masker/modified_bed/"
			out_file = genetype +"RM.bed"
			something = everything[everything.iloc[:,3].str.contains(genetype)]
			something.to_csv(os.path.join(out_dir, out_file),sep='\t',index=False)
		
#might cause a bug

rule pandas_search_from_modified_bed_part2:
	input:
		bedfile = 'Index_gen/Repeat_Masker/modified_bed/RNARM.bed'
#part 2 remove tRNA and rRNA
	output:'Index_gen/Repeat_Masker/modified_bed/RNAonlyRM.bed'
	run:
		import pandas as pd
		import os

		everything = pd.read_csv(input.bedfile ,sep="\t+",header=None)
		out_dir = "Index_gen/Repeat_Masker/modified_bed/"
		out_file = "RNAonlyRM.bed"
		rRNA = everything[everything.iloc[:,3].str.contains('rRNA')]
		tRNA = everything[everything.iloc[:,3].str.contains('tRNA')]
		something = pd.concat([everything,rRNA,tRNA]).drop_duplicates(keep=False)
		something.to_csv(os.path.join(out_dir, out_file),sep='\t',index=False, header=False)

#liftover does not work
#Gff3toBed also selects for pri-miRNA
rule liftover_mirbase21_to_dm6bed:
	input:
		dme3gff3 = 'Input_files/miRbase/dme.gff3',
		chainfile = 'Input_files/Lift_over/dm3ToDm6.over.chain',
		genome = 'Index_gen/Repeat_Masker/Index0.fa' 

	output:
		dme3bed	='Index_gen/Repeat_Masker/Liftover_files/mirbasedme3.bed',
		newFile = 'Index_gen/Repeat_Masker/Liftover_files/mirbase21_dm6.bed',
		unMapped ='Index_gen/Repeat_Masker/Liftover_files/liftover_unmapped',
		final_bed= 'Index_gen/Repeat_Masker/modified_bed/pri_miRNA_mirbase21_dm6.bed',
		fasta_out='Index_gen/Repeat_Masker/modified_bed/fasta/pri_miRNA.fa'
	params:
		Gff3toBed='Input_files/Awk_scripts/Gff3toBed.awk',
		RemoveChr='Input_files/Awk_scripts/RemoveChr.awk'
	shell:"""
		awk -f {params.Gff3toBed} {input.dme3gff3} > {output.dme3bed}
		liftOver {output.dme3bed} {input.chainfile} {output.newFile} {output.unMapped}
		awk -f {params.RemoveChr} {output.newFile} > {output.final_bed}
		bedtools getfasta -name -fi {input.genome} -bed {output.final_bed} -fo {output.fasta_out}
		"""

#install UCSC liftover, get chainfile from flybase, unzip with gzip -d	

rule copy_bed_files_from_gff_to_bed:
	input:
		source='Index_gen/Gff_to_bed/merged_bedfiles'
	output:
		outfile='Index_gen/Repeat_Masker/modified_bed',
		test_txt='Index_gen/Repeat_Masker/modified_bed.test.txt'
	shell:"""
	cp {input.source}/*merge.bed {output.outfile}
	touch {output.test_txt}
	"""

rule merge_bed_to_fasta:
#only for GFF from jinwee
	input:
		genome = 'Index_gen/Repeat_Masker/Index0.fa'

	output:
		test_text='Index_gen/Repeat_Masker/modified_bed/fasta/test2.txt'
	params:
		RemoveChr='BEGIN{}{gsub(/^chr/,""); print}END{}'
	run:
		import os
		from pathlib import Path
		Merge_bed=[]
		out_text_file=open(output.test_text,"w")
		out_dir=Path('Index_gen/Repeat_Masker/modified_bed/fasta')
		if out_dir.is_dir() != True:
			os.mkdir('Index_gen/Repeat_Masker/modified_bed/fasta')
		for file in os.listdir(os.path.join(os.getcwd(),'Index_gen/Repeat_Masker/modified_bed')):
			if file.endswith("merge.bed"):
				Merge_bed.append(file)
		for i in range(len(Merge_bed)):
			bed_file=os.path.join('Index_gen/Repeat_Masker/modified_bed/',Merge_bed[i])
			out_file=os.path.join('Index_gen/Repeat_Masker/modified_bed/fasta',Merge_bed[i][18:-10]+'.fa')
			shell('''awk {RemoveChr} {bed_file} > {bed_file}.nochr 
				bedtools getfasta -name -fi {input.genome} -bed {bed_file}.nochr -fo {out_file}''')
			out_text_file.write(Merge_bed[i]+'\n')
		out_text_file.close()
	
rule modified_bed_to_fasta:
#only for RM
	input:
		genome = 'Index_gen/Repeat_Masker/Index0.fa'

	output:
		test_text='Index_gen/Repeat_Masker/modified_bed/fasta/test.txt'
	run:
		import os
		from pathlib import Path
		out_text_file=open(output.test_text,"w")
		out_dir=Path('Index_gen/Repeat_Masker/modified_bed/fasta')
		if out_dir.is_dir() != True:
			os.mkdir('Index_gen/Repeat_Masker/modified_bed/fasta')
		for file in os.listdir(os.path.join(os.getcwd(),'Index_gen/Repeat_Masker/modified_bed')):
			if file.endswith("RM.bed"):
				Modified_bed_files.append(file)
		for i in range(len(Modified_bed_files)):
			bed_file=os.path.join('Index_gen/Repeat_Masker/modified_bed/',Modified_bed_files[i])
			out_file=os.path.join('Index_gen/Repeat_Masker/modified_bed/fasta',Modified_bed_files[i][:-6]+'.fa')
			shell('bedtools getfasta -name -fi {input.genome} -bed {bed_file} -fo {out_file}')
			out_text_file.write(Modified_bed_files[i]+'\n')
		out_text_file.close()
	
	
#do we want the individual fasta entry to be named?
#make modified_bed
rule remove_files:
	output: 'Index_gen/Repeat_Masker/modified_bed/RNAoRM.bed'
	shell:'''
	rm Index_gen/Repeat_Masker/modified_bed/RNARM.bed
	mv Index_gen/Repeat_Masker/modified_bed/RNAonlyRM.bed {output}
	rm Index_gen/Repeat_Masker/modified_bed/tRNARM.bed
	'''

rule move_other_fastas:
	input:
		genome = 'Index_gen/Repeat_Masker/Index0.fa'
	output:
		'Index_gen/Repeat_Masker/modified_bed/fasta/Index0.fa'
	shell:'''
	cp {input.genome} {output}
	'''
#also move the CR

rule hairpin_fa:
	input:
		genome = 'Index_gen/Repeat_Masker/Index0.fa',
		main='Index_gen/Gff_to_bed/dm6.17_flybase.gff'
	output:
		bed_file_temp='Index_gen/Repeat_Masker/modified_bed/flybasehpRNA.bed.temp',
		bed_file_temp_2='Index_gen/Repeat_Masker/modified_bed/flybasehpRNA.bed.2.temp',
		bed_file='Index_gen/Repeat_Masker/modified_bed/flybasehpRNA.bed',
		fasta_file='Index_gen/Repeat_Masker/modified_bed/fasta/flybasehpRNA.fa'
	params:
		grep='Name=hpRNA',
		gff_to_bed_hpRNA='Input_files/Awk_scripts/gff_to_bed_hpRNA.awk',
		RemoveChr='Input_files/Awk_scripts/RemoveChr.awk'

	shell:'''
	grep {params.grep} {input.main} > {output.bed_file_temp}
	awk -f {params.gff_to_bed_hpRNA} {output.bed_file_temp} > {output.bed_file_temp_2}
	awk -f {params.RemoveChr} {output.bed_file_temp_2} > {output.bed_file}
	bedtools getfasta -name -fi {input.genome} -bed {output.bed_file} -fo {output.fasta_file}
	'''

rule make_bt_indexes:
	input:
		fasta_file=expand(fasta_file_path)
	output:
		test_text='Index_gen/Repeat_Masker/modified_bed/fasta/bt_indexes/test.txt'
	run:
		import os
		out_text_file=open(output.test_text,"w")
		fasta_folder='Index_gen/Repeat_Masker/modified_bed/fasta'
		fasta_file_path=[]
		for file in os.listdir(os.path.join(os.getcwd(),fasta_folder)):
			if file.endswith(".fa"):
				fasta_file_path.append(os.path.join(fasta_folder,file))
		rename_dict={'Index0.fa':'Index0','rRNA.fa':'Index1','exon_PT_rRNA.fa':'Index2','CR14033.fa':'Index3','RNAonly.fa':'Index4','exon_PT_tRNA.fa':'Index5','exon_PT_snRNA.fa':'Index6','exon_PT_snoRNA.fa':'Index7','pri_miRNA.fa':'Index8','flybasehpRNA.fa':'Index9','LTR.fa':'Index10','LINE.fa':'Index11','DNA.fa':'Index12','Satellite.fa':'Index13','Low_complexity.fa':'Index14','RC.fa':'Index15','Simple_repeat.fa':'Index16','Other.fa':'Index17','Unknown.fa':'Index18','transposable_element.fa':'Index19','ARTEFACT.fa':'Index20'}
		for file in fasta_file_path:
			if file[len(fasta_folder)+1:] not in rename_dict:
				continue
			else:
				prefix=os.path.join('Index_gen/Repeat_Masker/modified_bed/fasta/bt_indexes',rename_dict[file[(len(fasta_folder)+1):]])
				shell('bowtie-build {file} {prefix}')
				out_text_file.write(file+'\n')
		out_text_file.close()


		